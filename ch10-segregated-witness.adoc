[[ch10]]
== Segregated witness - Fixing malleability and more
:imagedir: {baseimagedir}/ch10

This chapter covers

* Problems needing solutions
* Moving signatures out of transactions
* Deploying the solution (tough one!)

Bitcoin is far from perfect. There are several shortcomings that need
to be addressed. The first subsection of this chapter will explain
some shortcomings that Bitcoin suffers from. Among the most critical
ones are _transaction malleability_ and inefficiencies in signature
verification. We've already mentioned transaction malleability in
<<time-locked-transactions>>, that can cause a transaction to change
while being broadcast, and therefore its txid will change.

A solution to these problems was presented in 2015 at a conference on
Bitcoin scalability. This solution is known as _segregated witness_,
which is a weird name for moving signature data out of transactions.

We will descibe in detail this solution, which includes changes in
pretty much all parts of Bitcoin: Bitcoin addresses, transaction
format, block format, local storage and network protocol.

Since segregated witness was a pretty big change in Bitcoin, it was
not trivial to deploy without disrupting the network. It was carefully
designed so that old software would continue working and accepting
segregated witness transactions, though without verifying certain
parts of the transactions.

Last in this chapter we will explore blockchain forks. A blockchain
fork can occur when part of the Bitcoin network changes the consensus
rules. Forks come in different flavors; Soft forks and hard
forks. Both fork types change the rules, but in different
ways. Segregated witness was deployed as a soft fork.

=== Problems

This first subsection of the chapter will discuss the problems that
segregated witness, or segwit, intends to solve.

==== Transaction malleability

To explain transaction malleability, let's go back to the example in
<<ch09>> where you gave a time locked transaction to your
daughter. When almost a year has passed since you created the last
time locked transaction, you need to invalidate that transaction and
create a new one:

.You spend one of the outputs that the previous time locked transaction spends and create a new time locked transaction that you give to your daughter.
image::{imagedir}/inheritance-transaction.svg[{big-width}]

It was important to give the new time locked transaction, Tx~3~, to
your daughter before broadcasting Tx~2~ that invalidates the previous
time locked transaction, Tx~1~. Otherwise, if you broadcast Tx~2~
before giving Tx~3~ to your daughter, you may get hit by a bus between
the two steps. Then your daughter will not be able to claim the money.

So suppose that you do this correctly and first give Tx~3~ to your
daughter and then broadcast Tx~2~. Tx~3~ spends the output of Tx~2~,
which means that Tx~3~ contains the _transaction id_ of Tx~2~ in one
of its inputs.

Let's see what _may_ happen when you broadcast Tx~2~:

image::{imagedir}/tx2-malleated.svg[{half-width}]

Qi want to mess things up. When she receives your transaction Tx~2~,
she modifies it in a certain way, into Tx~2M~, so that Tx~2M~ is still
valid and has the same effect as the original transaction, Tx~2~. We
will see shortly different ways how that can be done. The result is
that there are now two different transactions that flow through the
network that spends the same outputs and sends the money to the same
recipients with the same amounts, but they have _different transaction
ids_.

Since Tx~2~ and Tx~2M~ spends the same outputs, they are in conflict
with each other and at most one of them will get confirmed. Suppose
that Tx~2M~ is the winner and gets mined in the next block. What
happens to your daughter's inheritance?

.Inheritance fails because your daughters time locked transaction is forever invalid due to transaction malleability.
image::{imagedir}/inheritance-fails.svg[{big-width}]

The _malleated_ transaction, Tx~2M~ is stored in the blockchain. That
makes Tx~2~ invalid because it spends the same output as Tx~2M~. The
first input of the time locked transaction that you gave to your
daughter contains the txid of Tx~2~, so when 2020-04-30 has passed,
your daughter will not be able to claim her inheritance because she
tries to spend an output from an invalid transaction.

===== How can Qi change the txid?

There are several options for Qi to change the scriptSig without invalidating the transaction. Among them are:

.Three classes of malleability issues.
image::{imagedir}/super-zoom-tx-malleability-problems.svg[{full-width}]

The first one modifies the signature container format, which changes
how the signature is written in the script sig. There are a few
different ways to _encode_ the signature that are all valid. Modern
versions of Bitcoin Core will relay transactions only if all
signatures are on the so-called "canonical" form. This means that it
will accept transactions in the blockchain using any of the encodings,
but not pass new transactions that aren't canonical. This is only a
partial solutions because transactions malleated this way can still
enter the blockchain.

The second way to malleate a transaction is by using cryptographic
tricks. I will not go into details here, because I'm not clever
enough. I can only say that a signature, regardless of format, can be
modified in a few ways that doesn't make them invalid. We only know
about one such trick, but we cannot rule out that there are others. A
relay policy is in place that prevents transactions with the known
trick to propagate. But as with the previous policy rule, you can't
really be sure it doesn't happen.

The last one is about changing the program itself. There are several
ways to to this. The one in the example above first duplicates
(OP_DUP) the top item on the stack and then immediately removes
(OP_DROP) the duplicate from the stack, effectively the change does
nothing and the whole program will run just fine. This type is also
limited by a relay policy that prohibits script operators other than
data pushes in the scriptSig.

While Bitcoin Core have implemented relay policies that decrease the
probability for transaction malleability, it can still happen. For
example, any miner can make such changes in any transaction before
including them in their blocks.

[[inefficient-sighash]]
==== Inefficient signature verification

This one is a bit more intricate. When a transaction is signed, the
signature algorithm will hash the transaction in a certain way, as we
saw in <<sighash-types>>.

As you remember from <<sign-transaction>> we clean all scriptSigs
before signing. But if we do _just_ that, all signatures of the
transaction would sign the exact same content. If the transaction
spends two different outputs to the same address, the signature in one
of the inputs could be reused in the other input. This can possibly be
exploited by bad actors.

To avoid this problem, Bitcoin makes each signature commit to slightly
different versions of the transaction by copying the spent
scriptPubKey into the scriptSig of the input that is currently being
signed.

Let's take the most common example of the `ALL` SIGHASH type without
`ANYONECANPAY` set and zoom in a bit on what's actually happening. The
first input is signed:

image::{imagedir}/sign-old-digest-1.svg[{half-width}]

The scriptSigs of all inputs are empty, but we copy the scriptPubKey
of the spent output and insert it into the scriptSig of the first
input. Then we create the signature for the first input. Then we move
on to sign the second input:

image::{imagedir}/sign-old-digest-2.svg[{half-width}]

Here all scriptSigs, except the second one is emtpy. The second
scriptSig is populated with the scriptPubKey of the spent output. Then
the signature is created.

By doing this exercise for each input we make sure that signatures are
not reusable across inputs if signed by the same private key. But this
also introduces a problem: Signature verification becomes inefficient.

Suppose that you want to verify the signatures of the above
transaction. For every input, you need perform basically the same
procedure as when the transaction was signed: Clean all the scriptSigs
from the transaction and then, one at a time, insert the scriptPubKey
in the scriptSig of the input you want to verify. Then verify the
signature for that input.

This may seem harmless, but as the number of inputs grow, the amount
of data to hash for each signature increases. If you double the number
of inputs, you

* double the number of signatures to verify
* double (roughly) the size of the transaction

[[sighash-n2]]
.Total time for hashing during signature verification. Time roughly quadruples when number of inputs double.
image::{imagedir}/sighash-n2.svg[{big-width}]

This means that if the time to verify the above transaction with two
inputs was 1 ms, it would take 4 ms to verify a transaction with 4
inputs. Double the number of inputs again, and we have 16 ms. A
transaction with 1024 inputs would take more than four minutes!

This weakness can be exploited by creating a large transaction with a
lot of inputs. All nodes verifying the transaction will be busy
verifying for minutes, this basically takes down the whole network for
as long as you want.

It would be much better if we could make the time grow linearly
instead of quadratic. Then the 1024 inputs would take roughly 512 ms
instead.

==== Waste of bandwidth

When a full node sends a transaction to a lightweight wallet, it sends
the complete transaction, which includes all signature data. But a
lightweight wallet cannot verify the signatures, because it doesn't
have the full history of transactions back to the coinbase
transactions.

The scriptSigs make a large percentage of the transaction size. A
typical scriptSig spending a p2pkh output takes 107 bytes. Consider a
few different transactions with two outputs:

.Space occupied by scriptSig data of different typical transactions
|===
| Inputs | Total scriptSig size | Tx size | scriptSig percentage

| 1 | 107 | 224 | 47%
| 2 | 214 | 373 | 57%
| 3 | 321 | 521 | 61%
| 8 | 856 | 1255 | 68%
|===


.Txid
****
image::{imagedir}/2ndcol-txid.svg[]
****

Wouldn't it be nice if a full node didn't have to send the scriptSig
data to the lightweight wallet? You would save more than 50% data
traffic. There's just one problem: They are needed to calculate
transaction ids. If you skip sending scriptSigs of transactions, the
lightweight wallet would not be able to verify that the transaction is
included in a block, because it can't verify the merkle proof. You do
remember how a lightweight wallet verifies a merkle proof, don't you?

.Without the scriptSigs, a lightweight wallet will not be able to verify that a transaction is included in the block.
image::{imagedir}/cannot-verify-tx-included-in-block.svg[{half-width}]

It would be nice if we could solve this somehow.

==== Script upgrades are hard

Sometimes it is desirable to extend the script language with new
operations. For example `OP_CHECKSEQUENCEVERIFY` and
`OP_CHECKLOCKTIMEVERIFY` were introduced in the language during 2015
and 2016. Let's have a look at how `OP_CHECKLOCKTIMEVERIFY`, CLTV, was
introduced.

Will start with what `OP_` codes actually are. They are nothing but a
single byte. `OP_EQUAL` for example, is represented by the byte `87`
in hex code. Every node knows that when they encounter the byte `87`
in the script program, they know that they need to compare the top two
items on the stack and push the result back on the
stack. `OP_CHECKMULTISIG` is also a single byte, `ae`. All operators are
represented by a different byte.

When Bitcoin was created, a number of "NOP" operators,
`OP_NOP1`-`OP_NOP10`, was specified. They are represented by the bytes
`b0`-`b9`. They are designed to do nothing. The name "NOP" comes from
"No OPeration" which basically means, "when this instruction appears
just ignore it and move on".

These NOPs can be used to extend the script language, but only to a
certain extent. The CLTV operator is actually `OP_NOP2`, or byte
`b1`. CLTV was introduced by simply to release a version of Bitcoin
Core that redefines how `OP_NOP2` works. But it needs to be done in a
compatible way so that we don't break compatibility with old,
non-upgraded nodes.

Let's go back to the example from <<absolute-time-locked-outputs>>
where you gave your daughter allowance in advance that she can cash
out on May 1:

.Using `OP_CHECKLOCKTIMEVERIFY` to lock an output until May 1.
image::{imagedir}/cltv-allowance.svg[{half-width}]

The scriptPubKey for this output is

[subs="normal"]
----
<may 1 2019 00:00:00> OP_CHECKLOCKTIMEVERIFY OP_DROP
OP_DUP OP_HASH160 <PKH~D~> OP_EQUALVERIFY 
OP_CHECKSIG
----

or at least, that's how a new node, that is aware of the new meaning
of byte `b1`, interprets the script. It will

* push the time `<may 1 2019 00:00:00>` to the stack
* *check that the lock time of the spending transaction has at least
   the value found on top of the stack. Fail immediately otherwise*
* drop the time value from the stack
* continue with normal signature verification

An old node, on the other hand will interprete the script as follows:

[subs="normal"]
----
<may 1 2019 00:00:00> OP_NOP2 OP_DROP
OP_DUP OP_HASH160 <PKH~D~> OP_EQUALVERIFY 
OP_CHECKSIG
----

It will

* push the time `<may 1 2019 00:00:00>` to the stack
* *do nothing*
* drop the time value from the stack
* continue with normal signature verification

Old nodes still treat `OP_NOP2` as it used to; By doing nothing and
move on. It is not aware of the new rules associated with the byte
`b1`.

The `OP_CHECKLOCKTIMEVERIFY` is carefully designed to make  `OP_DROP`
is included by the program author to make the script behave in the
same way if the script succeeds on

The old and the new nodes will behave the same if the
`OP_CHECKLOCKTIMEVERIFY` succeeds on the new node. But if the
OP_CHECKLOCKTIMEVERIFY fails on the new node, the old node will not
fail, because "do nothing" never fails. The new nodes fail more often
than the old nodes, because new nodes have stricter rules. The old
nodes will always finish the script program with success whenever the
new nodes finish with success. This is known as a _soft fork_. A soft
fork is a system upgrade that doesn't require all nodes to upgrade. We
will talk more about forks, system upgrades, and alternate currencies
born from Bitcoin's blockchain in the next chapter.

You may be wondering why the OP_DROP instruction is for. OP_DROP takes
the top item on the stack and discards it. OP_CHECKLOCKTIMEVERIFY is
designed to behave exactly like OP_NOP2 when it succeeds. The stack
must look exactly the same after operator has been run, regardless if
it's run as an OP_NOP2 by the old node or as `OP_CHECKLOCKTIMEVERIFY`
by a new node. If CLTV would be designed without taking old nodes into
account, it would probably take the top item from the stack. But since
we need to take old nodes into account, we cannot do that because the
change would not be compatible with old nodes. That's why we must add
the extra OP_DROP after OP_CHECKLOCKTIMEVERIFY.

The above was an example of how old script operators can be repurposed
to do something more strict without disrupting the whole network.

This method of script upgrades has been done for two operators so far.

|===
| Byte | Old code | New code | New meaning

| `b1` | `OP_NOP2` | OP_CHECKLOCKTIMEVERIFY | Verify that the spending tx has high enough absolute lock time
| `b2` | `OP_NOP3` | OP_CHECKSEQUENCEVERIFY | Verify that the spending input has high enough relative lock time
|===

There are only 10 spare operators that we can use for script upgrades,
and such upgrades are limited to mimic the `OP_NOP` behaviour if they
don't fail.

Sooner or later we need another script upgrade mechanism. Both because
we will run out of OP_NOPs and because we want the new script
operators to behave differently than OP_NOP when they succeed.

=== Solution

A solution to all the above problems were presented at a conference in
2015 by Pieter Wuille. The solution was to move the script out of the
transactions altogether.

Let's take a look again at the anatomy of a normal transaction:

.The txid is calculated from the whole transaction, including scriptSigs.
image::{imagedir}/normal-transaction.svg[{half-width}]

If we could just change the system so that the txid does not cover the
scriptSig, we would remove all known possibilities of unintentional
transaction malleability. Unfortunately, if we do this we would make
old software incompatible, because they calculate the txid in the
traditional way.

[.inbitcoin]
.BIP141
****
The new rules defined by segregated witness are specified in BIP141,
"Segregated Witness (Consensus layer)".
****

Segregated Witness, SegWit, solves the problem and all the above
mentioned problems in a forward and backward compatible way:

* Forward compatible because transactions and blocks created by new
  software works with old software.
* Backward compatible because transactions and blocks created by old
  software works with new software.

In crypto-lingo a _witness_ basically means a signature. It is
something that attests the authenticity of something. For a Bitcoin
transaction, the witness is the contents of the scriptSig program,
because that's what proves that the transaction is
authenticated. Segregated means parted, so we part the contents of the
scriptSig from the transaction, effectively leaving the scriptSig
empty:

.A segwit transaction has no signature data. The signatures are attached instead. The the txid does not commit to the signatures.
image::{imagedir}/segwit-transaction-simple.svg[{half-width}]

Segregated witness thus means that the contents of the scriptSig is
removed from the transaction and put into an external structure that
we call the witness.

We will follow a few segwit transactions to see how it affects the
different parts of the Bitcoin system. But first we need to get some
bitcoin into a segwit wallet.

==== Segwit addresses

Suppose that your wallet uses segwit, and that you are selling a
laptop to Amy. Your wallet needs to create an address that you can
give to Amy. So far nothing new.

But SegWit defines a new address type that is encoded using _Bech32_
instead of base58check. Your address is

 bc1qeqzjk7vume5wmrdgz5xyehh54cchdjag6jdmkj

This segwit address is a Bech32 encoding of the following pieces of
information.

 "bc"       "1"     00 c8052b799cde68ed8da8150c4cdef4ae3176cba8
 human-     delim-  data part
 readable   iter
 part

[.gbinfo]
.bc
****
`bc` is short for Bitcoin. Who could have guessed?
****

where `"bc"` is the so called human-readable part that represents the
type of the address, this is comparable with the `00` byte added
before the public key hash for legacy addresses. The `"1"` is a
delimiter between the human-readable part and the next part, the _data
part_. The data part contains the actual information that's going to
be used in the transaction. It consists of

* A version, 0 in this case
* A witness program, a public key hash
  (c8052b799cde68ed8da8150c4cdef4ae3176cba8) in this case

How the version and witness program is used will be covered in a later
subsection. You give the address
`bc1qeqzjk7vume5wmrdgz5xyehh54cchdjag6jdmkj` to Amy, by showing her a
QR code.
 
Amy scans this address, extracts the version and witness program, and
creates a transaction with a new kind of scriptPubKey that we are not
used to:

.Amy sends 0.1 BTC to your segwit address. scriptPubKey doesn't contain any script operators, just data.
image::{imagedir}/segwit-output.svg[{full-width}]

Amy broadcasts this transaction on the Bitcoin network. The network
will accept the transaction, because it is correctly signed in the old
fashioned way. Eventually it will get confirmed in a block. Your
wallet will acknowledge that you have actually received the money so
you give the laptop to Amy.

==== Spend your segwit output

Now that you have received your money you want to spend them on a used
popcorn machine. It costs only 0.09 BTC. It's a bargain! Suppose that
the owner of the popcorn machine has the segwit address
`bc1qlk349y63znw7up8wulw0rhvp02wptxul0qwrqp`.

.You create and broadcast a payment to the popcorn machine owner.
image::{imagedir}/segwit-spend-wpkh.svg[{big-width}]

Your transaction sends the money to the popcorn owner's segwit address
and pays 0.01 BTC in transaction fee. The input has an empty
scriptSig; The signature data is instead added as a _witness field_ in
the attached _witness_. Had there been multiple inputs in this
transactions, there would be multiple witness fields in the witness,
one for each input. You can mix segwit inputs and legacy inputs, in
which case the the witness fields for the non-witness inputs would be
empty, because their signatures are in the respective scriptSig, as
they always were.

==== Validate the segwit transaction

You have sent your transaction for the popcorn machine to the Bitcoin
peer to peer network for processing. Let's see how an upgraded full
node validates this transaction before relaying it to other
nodes. Since it's running the latest and greatest software, it knows
how to deal with segwit transactions.

.A full node verifies the witness of your transaction. The pattern `00` followed by exactly 20 bytes is treated special
image::{imagedir}/segwit-spend-wpkh-verify.svg[{big-width}]

[.gbinfo]
.Remember p2sh
****
You may have noticed that this is very similar to how p2sh worked in
<<p2sh-new-software>>. 
****

The full node, that knows about segwit, will look for a pattern in the
scriptPubKey starting with a single version byte followed by a 2 to 40
byte witness program. In this case the pattern matches, which means
that this is a segwit output.

Next step for the full node is to understand what kind of segwit
output it is. As of writing, there is only one version of segwit
output; Version `00`. This version comes in two different flavors:

* _p2wpkh_ (pay-to-witness-public-key-hash) identified by a 20 byte witness program
* _p2wsh_ (pay-to-witness-script-hash) identified by a 32 byte witness program

In this case we have the version byte `00` followed by exactly 20
bytes which means that this is a p2wpkh payment. If the version byte
is not zero, the node will immediately accept this input without
further processing. We'll talk a bit more on unknown versions later.

The p2wpkh is the simplest of the two types because it is very similar
to our well known p2pkh. Let's look at how they both work

p2pkh:: The scriptPubKey contains the actual script that checks the
signature in the scriptSig
p2wpkh:: The actual script is a pre-determined template and the
witness program _is_ the PKH to insert into the script template. The
signatures are taken from the witness.

In the end it's the exact same program that gets run for both of these
two types. The difference is where the components come from.

Why do this p2wpkh at all, when we are running the exact same script
program as in p2pkh? Let's recall that we want to solve transaction
malleability. We do that by removing the signature data from the
transaction inputs so that no one can change the transaction id by
making subtle changes to the scriptSig.

The full node has verified this transaction and sends it to its
peers. There's just one problem: One of the peers have no idea what
segwit is. It is an old node that hasn't been upgraded for a while.

===== "Validate" on old nodes

An old node has just received your transaction and wants to
verify it. Old nodes know nothing about segwit and that there are
witnesses attached to transactions. It will download the transaction
as it always has, which is without the witness attachment. This is
what the node will see:

.An old node will just see two data items in the scriptPubKey and an empty scriptSig.
image::{imagedir}/segwit-spend-wpkh-verify-old-node.svg[{big-width}]

Since the node doesn't know anything else, it will create the script
program by taking the empty scriptSig and append the scriptPubKey,
which will look like this:

 00 c8052b799cde68ed8da8150c4cdef4ae3176cba8

It will run this program. The program puts two data items on the
stack, first `00` then the `c805...cba8`. When it's done there is
nothing left to do but check whether the top item on the stack,
`c805...cba8`, is "true". Bitcoin defines anything that's non-zero to
be true, so this script will pass and the transaction is authorized.

This doesn't seems very secure. This is known as an "anyone can
spend", meaning that anyone can create a transaction that spends the
output. It requires no signature. You just have to create an input
with an empty scriptSig to take the money.

In <<ch11>> we will talk about how to deal with this problem. But for
now, suppose that 95% of the nodes run with segwit and someone tries
to use your output as an anyone-can-spend. Suppose also that this
transaction gets included in a block by some miner that don't know
about segwit. Then 95% of the network will not accept that block
because it contains an invalid transaction according to segwit
nodes. This means that the miner that defies the rules of the
_economic majority_ will lose their income.

==== Including your segwit transaction in a block

Your segwit transaction has propagated through the network, and all
nodes has verified it along the way. Now a miner wants to add the
transaction into a new block. Suppose that the miner runs modern
software and thus knows about segwit. Let's look at how it is included
in the block.

.Your segwit transaction gets included in a block. The block commits to the witnesses by putting the witness commitment into an output of the coinbase transaction.
image::{imagedir}/block-segwit.svg[{full-width}]

The block is built as before, but with one important difference. A new
block rule is introduced in segwit: If there are segwit transactions
in the block, the coinbase must contain an output with a _witness
commitment_. This witness commitment is the combined hash of the
_witness root hash_ and a _witness reserved value_. The witness root
hash is the merkle root of all _witness txids_ or _wtxids_ of all
transactions in the block. The wtxid is the hash of the transaction
_including the witness_ if there is one. There is an exception for the
coinbase, whose wtxid is always defined as just 32 zero bytes. The
witness reserved value is dedicated for future system upgrades.

The witness commitment is written in an `OP_RETURN` output:

.The coinbase transaction's witness contains the witness reserved value and an OP_RETURN output contains the witness commitment.
image::{imagedir}/segwit-coinbase-tx.svg[{half-width}]

The witness reserved value can be any value. But a full node verifying
this block needs a way to know what that value is. If the node didn't
know the witness reserved value, it wouldn't be able to reconstruct
the witness commitment for comparison with the OP_RETURN output's
witness commitment. The coinbase transaction's witness contains the
witness reserved value so that full nodes can verify the witness
commitment.

===== Old nodes verifying the block

The block above is valid for new segwit-enabled full nodes so it must
also be valid for old nodes that don't know what segwit is. An old
node will not download any witnesses from it peers, because it doesn't
know they exist.

.An old node verifies the block with your transaction. It will not verify the signatures or the witness commitment.
image::{imagedir}/block-segwit-old-node.svg[{half-width}]

This node will do what it has always done. Run the scripts of the
transactions, which will look like spending anyone-can-spend
outputs. That's ok, move on. If some of the transactions in the block
are non-segwit, those transactions will be fully verified.

We have now gone full circle with your transaction to the popcorn
machine owner who hands over the machine to you.

==== Pay to witness script hash

Do you remember when we introduced pay to script hash in
<<pay-to-script-hash>>? They were moving the actual scriptPubKey part
of the program to the spending input. Let's have another look at the
charity wallet that John, Ellen and Faiza set up.

.John and Faiza spends an output from their multisig wallet.
image::{imagedir}/p2sh-overview.svg[{big-width}]

The idea here was that the payer, the donor in this case, shouldn't
have to pay for a big complex scriptPubKey. Instead the recipient
wanting to use this fancy scheme will pay for the complexity.

With segwit we can do about the same thing. The segwit version of p2sh
is called pay-to-witness-script-hash, p2wsh. Isn't naming in Bitcoin
fantastic?

Suppose that John, Ellen and Faiza use SegWit for their charity wallet
and that the previous popcorn machine owner wants to give the money he
received for the popcorn machine to the charity.

John, Ellen and Faiza must provide the popcorn guy with a
pay-to-witness-script-hash address, a p2wsh address. Their _witness
script_ is the same as their p2sh _redeem script_ was when they were
using p2sh:

.The witness script is hashed into a witness script hash
image::{imagedir}/witness-script-and-wsh.svg[{half-width}]

They use this witness script hash to create a p2wsh address in the
same way that you created your p2wpkh address. They encode

 00 983b977f86b9bce124692e68904935f5e562c88226befb8575b4a51e29db9062

and get the p2wsh address

 bc1qnqaewluxhx7wzfrf9e5fqjf47hjk9jyzy6l0hpt4kjj3u2wmjp3qr3lft8

This address is handed to the popcorn guy who creates and broadcasts a
transaction like this:

.The popcorn guy sends the money to the charity's p2wsh address.
image::{imagedir}/tx-popcorn-guy-to-charity.svg[{big-width}]

The transaction has the witness attached just like your transaction to
the popcorn guy. The only difference between your transaction and the
popcorn guy's transaction is that the output has different length of
their witness programs. Your transaction had a 20 byte witness
program, because it was a public key hash, and the popcorn guy's
transaction has a 32 byte witness program, because that's a double
SHA256 of the witness script.

This transaction will get verified and eventually included in a block.

===== Spend the p2wsh transaction.

Suppose that John and Faiza wants to spend the 0.08 BTC they got from
the popcorn guy and send them to Amnesty International. Amnesty
happens to also have a p2wsh address. John and Faiza collaborate to
create the following transaction:

.The charity pays 0.07 BTC to Amnesty's address. The witness is the signatures followed by a data item that contains the actual witness script.
image::{imagedir}/tx-charity-to-amnesty.svg[{full-width}]

Note how there's nothing in the scriptSig. When we used p2sh in
<<pay-to-script-hash>>, the scriptSig got really big, because it
contained two signatures and the redeemScript, which in turn contained
three public keys.

===== Verifying the p2wsh input

A full node that wants to verify this transaction needs to determine
the type of output that is being spent. It looks at the output and
looks for the pattern `<version byte> <2 to 40 bytes data>`. It does find this
pattern and concludes from this that this is a segwit output. Next
thing to check is the value of the version byte.

.Preparing to verify the p2wsh input
image::{imagedir}/segwit-spend-wsh-verify-1.svg[{big-width}]

The version byte is `00`. A version `00` segwit output can have two
different lenghts of the witness program, 20 or 32 bytes. The first
one was covered in previous sections on p2wpkh. The witness program in
this example is 32 bytes, which means that this is a
pay-to-witness-script-hash, p2wsh, output.

Special rules apply when spending a p2wsh output. First, the data
items in the witness field of the spending input is pushed onto the
program stack in the order they appear in the witness field.

Then the top item on the stack, the witness script, is verified
against the witness program in the output.

.Verifying the witness of a p2wsh payment.
image::{imagedir}/segwit-spend-wsh-verify-2.svg[{big-width}]

The witness script is hashed and compared to the witness program in
the spent output before being executed with the three items on the
stack. This process is similar to that of verifying p2sh payment.

All segwit transactions are handled the same way by miners and block
verifiers, so there's no difference in how the transaction is included
and verified in a block compared to p2wpkh transactions.

==== New hashing method for signatures

[.inbitcoin]
.BIP143
****
This solution is specified in BIP143, "Transaction Signature
Verification for Version 0 Witness Program"
****

One of the problems segwit solves is the inefficient signature
hashing. As explained in <<inefficient-sighash>>, if the number of
inputs doubles, the time it takes to verify the transaction roughly
quadruples.

The solution is to make the signatures in steps. Suppose that you want
to sign all four inputs of a transaction:

.Hashing is done in two steps. The intermediate hash is reused for each input.
image::{imagedir}/new-sighash-algo.svg[{big-width}]

1. Make a reusable hash, intermediate hash
2. Extend the reusable hash with stuff specific to the current input

The intermediate hash commits to all inputs and outputs of the
transaction. Then, for each input add the intermediate hash to some
input-specific data:

Spent outpoint:: The transaction id and index of the output that this input spends
Spent output script:: The scriptPubKey of the spent output
Spent amount:: The BTC value of the spent output.

.Old hashing
****
image::{imagedir}/2ndcol-sighash-n2.svg[]
****

The bulk of the transaction is only hashed once to create the
intermediate hash. This reduces the amount of hashing needed. When the
number of input doubles, the amount of hashing only doubles. This
makes the hashing algorithm perform _linearly with number of inputs_
instead of _quadratic_. The time to verify the transaction with 1024
inputs in <<sighash-n2>> would be reduced from 262144 ms to
512 ms.

===== Signature commits to spent amount

But why do we include the spent amount? We didn't do that in the old
signature hashing algorithm. This has nothing to do with hashing
efficiency, but it fixes yet another problem that off-line wallets and
some lightweight wallets face.

An off-line wallet, for example a hardware wallet, cannot know how
much money is being spent. If an unsigned transaction is to be signed
by the off-line wallet, the wallet cannot display the fee amount of
the transaction to the user because it cannot see the values of the
outputs it is spending.

.An off-line wallet cannot know the fee of a transaction.
image::{imagedir}/fee-unknown.svg[{half-width}]

This is true for both non-segwit and segwit transaction. However, with
segwit, when the signatures commit to the spent output amounts, the
wallet must get the amounts from somewhere to be able to sign. Suppose
that the input amounts are somehow input to the off-line wallet, for
example through a USB memory stick alongside the transaction to
sign. Then the wallet can sign the transaction using those amounts and
even show the user what fee is being paid before signing.

If the wrong amount is being sent to the off-line wallet, it wouldn't
be able to tell. It cannot verify the input values. But since the
signatures now cover the amounts the transaction would be invalid. A
verifying node will know the correct amounts and use the correct
amounts when verifying the signatures. The signature check will
fail. The new signature hashing algorithm makes it impossible to trick
a wallet into signing a valid transaction with a fee the user didn't
intend.

==== Bandwidth savings

Since segwit removes the signature data from the transaction. When a
lightweight wallet requests a transaction from a full node, the full
node can send the transaction without the witness data. This means
that less data traffic is needed per transaction. This fact can be
used to either

* keep the bloom filter size as is and get about 50% reduction in data
  traffic.
* improve privacy by decreasing the size of the bloom filter to get
  more false positives.

==== Upgradeable script

The version byte is used for future upgrades of the script
language. Before segwit, we had to use the OP_NOPs to introduce new
features to the language, for example OP_CHECKSEQUENCEVERIFY. This was
not optimal, because

* We may run out of OP_NOPs, there are 8 left.
* The OP_NOPs cannot be redefined in arbitrary ways, they still need
  to behave as OP_NOP in case the new behaviour succeeds.

The version byte allows for much more powerful future upgrades. We can
do anything from slight modifications of specific operators, to
implementing completely new languages.

=== Wallet compatibility

Most old wallet will not support sending bitcoin to a segwit
address. They usually only allow p2pkh and p2sh addresses. For this
reason the developers of segwit created _p2wsh nested in p2sh_, and
_p2wpkh nested in p2sh_. These are two other ways to trigger the
segwit verification instead of the legacy script verification.

Suppose that you have a segwit wallet and want to sell your popcorn
machine to your neighbor, Nina. But Nina doesn't have a segwit
wallet. She can only pay to ordinary addresses like p2pkh and p2sh.

You can make a p2sh address that Nina can pay to:

.Nina uses her old wallet to your segwit wallet using a p2wpkh inside a p2sh address.
image::{imagedir}/p2wpkh-in-p2sh.svg[{half-width}]

Nina pays to `3KsJCgA6ubxgmmzvZaQYR485tsk2G6C1Be` which is an old
style p2sh address that contains the hash of the redeem script `00
bb4d49777d981096a75215ccdba8dc8675ff02d1`. This redeem script is a
version byte `00` followed by a 20 byte witness program. That is the
pattern for p2wpkh which we covered a few sections back.

Nina's wallet knows nothing about this. It sees only a p2sh address
and makes a payment to that script hash.

Later, when you want to spend your output, you create a transaction
like this:

.You spend the money you got from Nina by setting the version byte and witness program in the scriptSig of your input.
image::{imagedir}/p2wpkh-in-p2sh-spend.svg[{big-width}]

You create a witness just as you would with a normal p2wpkh input, but
you also set the redeem script in the scriptSig. The redeem script
happens to be a version byte followed by your 20 byte public key
hash. Using this scriptSig, old nodes can verify that the script hash
in the spent output matches the redeemScript in the scriptSig. New
nodes will detect that the redeemScript is a version byte and a
witness program and verify the witness accordingly.

This way of nexting a segwit payment inside a p2sh payment can also be
used for p2wsh payments in a similar fashion, a so-called _p2wsh
nested in p2sh_.

=== Recap of payment types

We have talked about several standard types of payments. Let's summarize them:

[cols="h,4*"]
|===
| Short name | Address format | scriptPubKey | scriptSig | witness field

| p2pkh | `**1**5vwoaN74MBeF5nr2BH4D KqndEFjHA6MzT` | Actual script | pubkey and signature | -
| p2sh | `**3**28qTX1KYxMohp4MjPPED BoRomCGwrB2ag` | Script that verifies redeem script hash | signatures plus the actual redeem script | -
| p2wpkh | `**bc1**qeqzjk7vume5wmrdgz 5xyehh54cchdjag6jdmkj` | 00 <pkh> | - | pubkey and signature
| p2wsh | `**bc1**qnqaewluxhx7wzfrf9 e5fqjf47hjk9jyzy6l0hp t4kjj3u2wmjp3qr3lft8` | 00 <witness script hash> | - | signatures plus the actual witness script
| p2wpkh in p2sh | `**3**28qTX1KYxMohp4MjPPED BoRomCGwrB2ag` | script that verifies redeem script hash | one item containing version byte and pkh | pubkey and signature
| p2wsh in p2sh | `**3**28qTX1KYxMohp4MjPPED BoRomCGwrB2ag` | script that verifies redeem script hash | one item containing version byte and witness script hash | signatures plus the actual witness script
|===

=== Block limits

Bitcoin blocks are limited at 1,000,000 bytes and 20000 signature
operations.

==== Signature operations limit

This is put in place because of the inefficient signature hashing
algorithm described in <<inefficient-sighash>>. An attacker could
create a very big transaction that contains thousands of inputs and
put it in a block. This would stall all nodes verifying the block for
a very long time, even several minutes. With this limit, the effect of
this attack is limited.

==== Block size limit

In 2010 the bitcoin software was updated with a limit of 1,000,000
bytes. It is not totally clear why this was done, but most people seem
to think that the limit was introduced to reduce the impact of certain
denial-of-service attacks.

One way to mess with the network is to create and a very large block
that takes 10 seconds to download on a good internet connection. That
may seem fast enough, but uploading this block to 5 peers will take 50
seconds, provided that your peers have the same internet speed as you
have. This will cause the block to propagate very slowly across the
peer to peer network, which will increase the risk of an unintended
blockchain fork. Unintended forks will resolve with time, as we saw in
<<draw-lucky-numbers>>, but the overall security of Bitcoin will
decrease during such forks.

Another potential problem with big blocks is that people with poor
internet connections will be left out completely, because they simply
cannot keep up with the network because they don't have the required
network capacity, processing power, primary or secondary memory needed
to run a full node. These people will need to switch to systems with
less security like lightweight wallets.

Regardless of the reason, this limit is in place. It will take a so
called hard fork to remove or increase this limit. A hard fork is a
rule change that causes old nodes and new nodes to disagree on what
the strongest valid blockchain is. We will examine forks and upgrades
in <<ch11>>. For now, suppose that new nodes decides that 8,000,000
byte blocks are ok. When a miner publishes a block that is bigger than
1,000,000 bytes, new nodes will accept it while old nodes will not
accept it and a permanent fork has occurred, and we effectively have
two different cryptocurrencies.

With segwit, there is an opportunity to somewhat increase the block
size limit without a hard fork. The old rule of 1,000,000 bytes
remains, so old nodes can continue working as they used to. However,
new nodes will count block size differently, but in a
compatible way. Witness bytes will be counted with a "discount"
compared to other bytes, such as the block header or transaction
outputs. A new measurement, _block weight_, is put in place. The
maximum _weight_ of a block is 4,000,000 _weight units_, WU:

.The maximum block weight calculates witness bytes and other bytes differently. Witness bytes contribute less to the block weight.
image::{imagedir}/block-weight.svg[{big-width}]

Let's call the block excluding the witnesses _base block_.

* 1 byte of base block data is counted as 4 weight units
* 1 byte of witness data is counted as 1 weight unit

The effect is that the old 1,000,000 byte block size limit remains
because the new rule and the old rule are effectively the same on the
base block. But the more segwit is used, the more data can be moved
from the base block to the witness, which allows for a bigger total
block size.

Suppose that only segwit transactions are used and the witnesses
account for r of all transaction data. The maximum block weight is
4,000,000 and a total block size T gives us

[stem]
++++
3T(1-r)+T=4*10^6 \\
T=\frac{4*10^6}{3(1-r)+1}
++++

Inserting r into this formula gives us different maximum total block sizes:

|===
| r [witness bytes/total bytes] | Max total block size [bytes]

| 0	| 1,000,000
| 0.1	| 1,081,081
| 0.2	| 1,176,471
| 0.3	| 1,290,323
| 0.4	| 1,428,571
| 0.5	| 1,600,000
| 0.6	| 1,818,182
| 0.7	| 2,105,263
| 0.8	| 2,500,000
| 0.9	| 3,076,923
|===

You can see that as the amount of witness data increases in the block,
we can squeeze in more transactions. The effect is an actual block
size increase.

There are a number of reasons for why the witness discount is
implemented:

* give wallet developers, exchanges and smart contract developers
  incentive to make less outputs to reduce the size of the
  UTXO set. For example an exchange may chose to consolidate their
  many outputs into a few outputs.

* Old nodes don't download witness data, which means that witness data
  doesn't affect the network as much as other parts of the
  transactions.

* The witnesses doesn't have to be sent to lightweight wallet.





=== Summary

=== Exercises

==== Warm up

==== Dig in

=== Recap




Also, as we discussed in <<validating-early-blocks>>, a full node that
does the initial blockchain download, may chose not to verify any
signatures before a certain block. This would also open up the
possibility for the node to skip downloading and storing the
scriptSigs.

* Witness data becomes cheaper because it can be pruned

* Allow 1 000 000 bytes but count a witness byte as 0.25 bytes, effectively increasing the block size.

* scriptPubKey = 0 <witness program>, scriptSig = (empty), witness = ...input... <script> (a bunch of pushes)
* New wtxid
* Witness merkle root in an OP_RETURN output of the coinbase



75% Discount because signatures doesn't go into the UTXO set.

Explain Bech32.

Bitcoin's confirmation times (several minutes) and relatively high
transaction fees, see <<bitcoin-at-a-glance>>, can be a showstopper
for small quick payments, like when you buy your morning coffee on
your way to work. You don't want to wait 10 minutes at the cafe. We
noted in <<when-not-to-use-bitcoin>> that technical solutions are on
their way to solve this problem. We will explain payment channels that
lets you make tiny payments nearly instantaneous. Payment channels
lays the groundworks for higher level systems, like the Lightning
Network.


Add to chaper 5 that p2sh is good because it moves fee burden from
sender to recipient.

Add transaction version to transactions in chapter 9. Also mention it
in ch5 where we mention locktime and sequence.


Describe soft forks and hard forks and how segwit got deployed.


Open questions:

* Does anyone here know why the sequence of other inputs are zeroed when signing with SIGHASH_NONE or SIGHASH_SINGLE? Doesn't that interfere with relative lock time and RBF opt-in?

* Why do Bernanke outputs have values >0? Do they have to?

* 

Closed questions:

* Can we really save storage and or bandwidth between full nodes with SegWit?
** Yes, but not right now. Witnessless mode is not implemented.

* How can you make a relative lock-time transaction that is not opt-in RBF?
** opt-in is seq<0xffffffff-1 while rel-lock-time is 0x7fffffff-0x00000000

* Is it possible that there are other yet unknown ways to malleate a signature than the "-S" trick? Or maybe even known ones? I refer only to inherent ECDSA signature malleability.
** Yes it's possible according to wumpus in bitcoin-core-dev

payment channel
lightning


